# This script covers both basic and advanced AI/ML concepts using Pandas and other essential libraries.
# Here's an overview of what it includes:

# Pandas Basics for AI/ML:
# 1. Creating and Manipulating DataFrames - Working with structured tabular data.
# 2. Reading and Writing CSV Files - Loading and saving datasets.
# 3. Data Exploration - Checking data info, statistics, and filtering.
# 4. Handling Missing Values - Filling NaN values with mean/median values.
# 5. Grouping and Sorting - Aggregating data for better insights.

# Advanced AI/ML Topics:
# 1. Feature Engineering - Creating new features like log transformation.
# 2. Dimensionality Reduction - Using PCA to reduce data dimensions.
# 3. Clustering - Applying K-Means for unsupervised learning.
# 4. Regression Models - Building a Linear Regression model.
# 5. Classification Models - Using Random Forest for binary classification.
# 6. Deep Learning - Defining a neural network using TensorFlow/Keras.
# 7. Natural Language Processing (NLP) - Text vectorization with TF-IDF.
# 8. Reinforcement Learning - Setting up an OpenAI Gym environment.
# 9. Generative Adversarial Networks (GANs) - Building a GAN generator model.

# This repository will help you build a strong AI/ML foundation while also covering state-of-the-art topics.

import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
from tensorflow import keras
from sklearn.feature_extraction.text import TfidfVectorizer
import gym
from tensorflow.keras.layers import Dense, LeakyReLU

# Creating a simple DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],
        'Age': [25, 30, 35, 40],
        'Salary': [50000, 60000, 70000, 80000]}
df = pd.DataFrame(data)
print("DataFrame:")
print(df)

# Reading a CSV file
# df = pd.read_csv('data.csv')

# Display basic information
print("\nBasic Info:")
print(df.info())

# Display summary statistics
print("\nSummary Statistics:")
print(df.describe())

# Selecting specific columns
print("\nSelecting 'Name' column:")
print(df['Name'])

# Filtering data
print("\nPeople with Age > 30:")
print(df[df['Age'] > 30])

# Adding a new column
df['Bonus'] = df['Salary'] * 0.1
print("\nDataFrame with Bonus Column:")
print(df)

# Dropping a column
df = df.drop(columns=['Bonus'])
print("\nDataFrame after Dropping Bonus Column:")
print(df)

# Sorting data by Age
print("\nSorted by Age:")
print(df.sort_values(by='Age'))

# Handling missing values
data_with_nan = {'Name': ['Alice', 'Bob', 'Charlie', None],
                 'Age': [25, 30, None, 40],
                 'Salary': [50000, 60000, 70000, None]}
df_nan = pd.DataFrame(data_with_nan)
print("\nDataFrame with NaN:")
print(df_nan)

# Filling missing values
df_nan_filled = df_nan.fillna({'Name': 'Unknown', 'Age': df_nan['Age'].mean(), 'Salary': df_nan['Salary'].median()})
print("\nDataFrame after Filling NaN:")
print(df_nan_filled)

# Grouping data
grouped = df.groupby('Age').mean()
print("\nGrouped by Age:")
print(grouped)

# Saving to a CSV file
df.to_csv('output.csv', index=False)

# Advanced AI/ML Topics

# Feature Engineering
print("\nFeature Engineering - Creating New Features:")
df['Salary_Log'] = df['Salary'].apply(lambda x: np.log(x))
print(df)

# Dimensionality Reduction
pca = PCA(n_components=2)
pca_result = pca.fit_transform(df[['Age', 'Salary']])
print("\nPCA Reduced Data:")
print(pca_result)

# Clustering
kmeans = KMeans(n_clusters=2)
df['Cluster'] = kmeans.fit_predict(df[['Age', 'Salary']])
print("\nK-Means Clustering:")
print(df)

# Regression Model
X = df[['Age']]
y = df['Salary']
model = LinearRegression()
model.fit(X, y)
print("\nLinear Regression Coefficients:")
print(model.coef_, model.intercept_)

# Classification Model
y_class = (df['Salary'] > 65000).astype(int)  # Converting Salary to binary class
clf = RandomForestClassifier()
clf.fit(X, y_class)
print("\nRandom Forest Classifier Predictions:")
print(clf.predict(X))

# Deep Learning
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(1,)),
    keras.layers.Dense(1, activation='linear')
])

model.compile(optimizer='adam', loss='mean_squared_error')
print("\nDeep Learning Model Summary:")
model.summary()

# Natural Language Processing (NLP)
text_data = ["AI is amazing", "Machine learning is fun", "Deep learning is powerful"]
vectorizer = TfidfVectorizer()
X_text = vectorizer.fit_transform(text_data)
print("\nTF-IDF Vectorized Text Data:")
print(X_text.toarray())

# Reinforcement Learning
env = gym.make("CartPole-v1")
print("\nReinforcement Learning Environment:")
print(env)

# Generative Adversarial Networks (GANs)
generator = keras.Sequential([
    Dense(128, activation=LeakyReLU(0.2), input_shape=(100,)),
    Dense(256, activation=LeakyReLU(0.2)),
    Dense(28*28, activation='sigmoid')
])
print("\nGAN Generator Model Summary:")
generator.summary()
